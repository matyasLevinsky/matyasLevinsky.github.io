[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Hello, I am Matyas Levinsky a sociology student at the philosophical faculty of the Charles University. This page serves to show rendered content from my repositories and is currently a work in progress."
  },
  {
    "objectID": "index.html#uploaded-projects",
    "href": "index.html#uploaded-projects",
    "title": "Welcome",
    "section": "Uploaded projects",
    "text": "Uploaded projects\n\nFebruary 2024\nCNN reporting analysis\nI investigated how CNN reported on the mass shooting that happened on the 21.12.2023 at my University."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Hello, I am Matyáš Levínský a sociology student at the philosophical faculty of the Charles University in Prague. I am primarily interested in the precarization of work due to the Gig economy, and AI. I try to follow hot topics, and as such am interested in AI itself."
  },
  {
    "objectID": "content/SlerkaProjekt.html",
    "href": "content/SlerkaProjekt.html",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "",
    "text": "Given that the University shooting that happened on the 21 December 2023 was unprecedented in Czech history, I wondered whether it would be reflected as such in american media that has grown increasingly desensitized to news of mass shootings."
  },
  {
    "objectID": "content/SlerkaProjekt.html#getting-the-data",
    "href": "content/SlerkaProjekt.html#getting-the-data",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Getting the data",
    "text": "Getting the data\nI wanted to compare the mass shooting to comparable reporting about mass shootings using the same live-block format CNN used for the Prague shooting. I used the first 12 articles that popped up for the Google search ‘site:cnn.com “mass shooting” live-news’ and filtering for articles in 2023-2024.\nI created a list of the necessary URLs and a couple of helper functions: readUrlList, parseUrlList and generateTeiCorpus. They are simple for-loops that do what their name suggest. Let’s load them together with the packages we will need.\n\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(janitor)\nlibrary(here)\nsource(here(\"content/helperCNNAnalysis.R\"))\n\nNow we can use them to read and parse the HTML of the CNN live-blogs. This may take some time so lets save it for later. If the code should be broken I have provided my own webscrape from 28.02.2024.\n\nhtmlList &lt;- readUrlList(urlList, silent = T)\nparsedDt &lt;- parseUrlList(htmlList, silent = T)\nsaveRDS(parsedDt, file = \"parsedDt_WebscrapingCNN.rds\")\nparsedDt\n\nAlternative:\n\nparsedDt &lt;- readRDS(here(\"content/parsedDt_WebscrapingCNN.rds\"))\nparsedDt\n\n\n\n  \n\n\n\nAs we can see, we don’t realy see the articel text (the last column “liveBlogUpdate”) we need to unnest the data and fix the column names while we are at it.\n\nblogPostsExpanded &lt;- parsedDt %&gt;%\n  unnest(cols = c(liveBlogUpdate), names_sep = \"_blog\") %&gt;% \n  rename_with(~ str_replace_all(.x, \"[@\\\\$]\", \"\")) %&gt;% \n  select(mainEntityOfPage:datePublished, author:liveBlogUpdate_blogheadline, liveBlogUpdate_blogauthor:liveBlogUpdate_blogarticleBody)\n\nblogPostsExpanded"
  },
  {
    "objectID": "content/SlerkaProjekt.html#tei-conversion",
    "href": "content/SlerkaProjekt.html#tei-conversion",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "TEI conversion",
    "text": "TEI conversion\nSome tools require a TEI compatible corpus such as: https://voyant-tools.org/. We will now convert our data:\n\nblogTEI &lt;- blogPostsExpanded %&gt;% \n  mutate(\n    MetadataColumn = paste0(\"eventName: \", about$name, \"headline:\", liveBlogUpdate_blogheadline), \n    TextColumn = liveBlogUpdate_blogarticleBody\n  )\n\ndescription &lt;- paste0(\"A TEI corpus containg \", length(blogTEI), \" live blogpost from CNN about mass shootings.\")\n\nprague &lt;- generateTeiCorpus(MetadataColumn = blogTEI$MetadataColumn, TextColumn = blogTEI$TextColumn, MetadataSting = description, silent = T)"
  },
  {
    "objectID": "content/SlerkaProjekt.html#analysis-in-r",
    "href": "content/SlerkaProjekt.html#analysis-in-r",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Analysis in R",
    "text": "Analysis in R\nIf we want to keep analyzing in R we have multiple options. I would refer you to the great book ‘Text Mining with R’. Let’s use the tidytext and textdata packages to do a simple sentiment analysis. First we need to shape our data accoringly.\n\nlibrary(tidytext)\nlibrary(textdata)\n\n# Analysis\nreducedTb &lt;- blogPostsExpanded %&gt;% \n  unnest(cols = c(about)) %&gt;% \n  select(name, liveBlogUpdate_blogheadline, liveBlogUpdate_blogarticleBody) %&gt;% \n  rename(\"headline\" = liveBlogUpdate_blogheadline, \"text\" = liveBlogUpdate_blogarticleBody) %&gt;% \n  mutate(\n    text = tolower(text),\n    name = gsub(\"April 10, 2023: |April 11, 2023 - |Live updates: |March 27, 2023 |May 3, 2023 - |October 25, 2023 - \", \"\", name), \n    name = str_wrap(name, width = 40)\n    ) %&gt;%\n  unnest_tokens(word, text) %&gt;% \n  anti_join(stop_words, by = \"word\")\n\nNrcSentiments &lt;- get_sentiments(\"nrc\") # Get the sentiment database\n\n# Join our webscraped date with the sentiment file\narticlesSentiment &lt;- reducedTb %&gt;%\n  inner_join(NrcSentiments, by = \"word\", relationship = \"many-to-many\") %&gt;%\n  count(name, sentiment) %&gt;%\n  pivot_wider(names_from = sentiment, values_from = n) %&gt;% \n  mutate(\n    total = rowSums(select(., anger:trust)),\n    other = rowSums(select(., c(disgust, joy, surprise))),\n    reducedTb %&gt;% group_by(name) %&gt;% summarise(articles = n_distinct(headline)) %&gt;% select(\"articles\"), # Direct add articles\n    across(anger:other, ~ .x / total, .names = \"{.col}Prop\")\n  )\n\n# Pivot into a long format for the purpose of plotting\narticlesSentimentLong &lt;- articlesSentiment %&gt;% \n  select(name, angerProp, anticipationProp, fearProp, negativeProp:sadnessProp, trustProp, otherProp) %&gt;% \n  pivot_longer(cols = angerProp:otherProp,  names_to = \"emotion\", values_to = \"prevalence\") %&gt;% \n  mutate(emotion = gsub(\"Prop\", \"\", emotion))\n\nunique(articlesSentimentLong$emotion)\n\n[1] \"anger\"        \"anticipation\" \"fear\"         \"negative\"     \"positive\"    \n[6] \"sadness\"      \"trust\"        \"other\"       \n\n\nWe have reduced our data and joined it with the sentiment database nrc published by Saif Mohammad and Peter Turney. After that we computed rowSums and ‘rowAverages’, finally we converted the data into a long format for the purpose of plotting. For that we will be using the packages ggplot2 and scales.\n\nlibrary(ggplot2)\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nggplot(articlesSentimentLong) +\n  aes(x = name, y = prevalence, fill = emotion) +\n  geom_col() +\n  geom_text(\n    aes(label = percent(prevalence, accuracy = 0.1)),\n    nudge_y = if_else(articlesSentimentLong$prevalence &gt; .15, -.05, .05),  \n    size = 3, \n    color =  \"black\") + \n  coord_flip() +\n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        axis.text.x = element_blank(), \n        axis.title.x = element_blank(), \n        axis.title.y = element_blank(), \n        legend.position = \"none\") +\n  facet_grid(~ emotion)"
  },
  {
    "objectID": "content/SlerkaProjekt.html#expandin-on-that-analysis-latent-dirichlet-allocation",
    "href": "content/SlerkaProjekt.html#expandin-on-that-analysis-latent-dirichlet-allocation",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Expandin on that analysis: Latent Dirichlet allocation",
    "text": "Expandin on that analysis: Latent Dirichlet allocation\nLatent Dirichlet allocation (LDA) is a particularly popular method for fitting a topic model. It treats each document as a mixture of topics, and each topic as a mixture of words. We will use it to give some oomph to our analysis. For that we will be using the package topicmodels. We will also have to adapt the shape of our data:\n\nlibrary(topicmodels)\n\nremoveWords &lt;- c(\"cnn\", \"p.m\")\ntoRemoveDf &lt;- tibble(document = NA, word = removeWords, n = 1)\n\n# Dataformatting\n# Need one-term-per-document-per-row\n\nDtmData &lt;- reducedTb %&gt;% \n  group_by(name, headline) %&gt;% \n  count(word, sort = T) %&gt;% \n  ungroup() %&gt;% \n  mutate(document = paste0(name, \"_\", headline)) %&gt;% \n  select(document, word, n) %&gt;% \n  anti_join(toRemoveDf, by = \"word\")\n\nhead(DtmData, 5)\n\n\n\n  \n\n\n\nNow that our data is in an appropriate format we can start modeling. As we know that there are 12 Events we have scraped from the Web we can input that for gaining an optimal model. (I have attempted other values, the results were less thatn stellar.)\n\ncastData &lt;- cast_tdm(data = DtmData, term = document, document = word, value = n) # reverse necessary\n\ncastData\n\n&lt;&lt;TermDocumentMatrix (terms: 432, documents: 3991)&gt;&gt;\nNon-/sparse entries: 20266/1703846\nSparsity           : 99%\nMaximal term length: 180\nWeighting          : term frequency (tf)\n\nmodel1 &lt;- LDA(castData, k = 12, control = list(seed = 1234)) # reverses, see above\n  \nmodel1\n\nA LDA_VEM topic model with 12 topics.\n\nmodel1Topics &lt;- tidytext::tidy(model1, matrix = \"beta\")\n\nmodel1Topics\n\n\n\n  \n\n\n\nYou might have noticed the issue with the reverse naming of document and word. For some reason there happens a switch in the LDA() step, that I was unable to diagnose, so this is my shoddy workaround. Now that we have the model we can look how certain terms are present in the models 12 topics. Remember that the topics were set by the model itself and not by us. Therefor we can evaluate if the topic are sensible to our human preferences.\n\nshootingTopTerms &lt;- model1Topics %&gt;%\n  group_by(topic) %&gt;%\n  slice_max(beta, n = 10) %&gt;% \n  ungroup() %&gt;%\n  arrange(topic, -beta)\n\nshootingTopTerms %&gt;%\n  mutate(term = reorder_within(term, beta, topic)) %&gt;%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered()\n\n\n\n\nWe are mostly interested in plot nr. 11 that is showing the language used during the reporting on the Prague mass shooting. To my sensibilities the graph make sense and so I will continue with the analysis. To determine whether the Prague shooting was a routing reporting experience for the writers at CNN we can look whether the articles themselves are significantly different. For that purpose we will separate the individual articles from their Events and look how many the model can correctly allocate to the correct topic.\n\nmodel1Gamma &lt;- tidytext::tidy(model1, matrix = \"gamma\")\n\nmodel1Gamma\n\n\n\n  \n\n\nseparatedGamma &lt;- model1Gamma %&gt;%\n  separate(document, c(\"Event\", \"Headline\"), sep = \"_\", convert = TRUE)\n\nseparatedGamma\n\n\n\n  \n\n\nseparatedGamma %&gt;%\n  mutate(title = reorder(Event, gamma * topic)) %&gt;%\n  ggplot(aes(factor(topic), gamma)) +\n  geom_boxplot() +\n  facet_wrap(~ Event) +\n  labs(x = \"topic\", y = expression(gamma))\n\n\n\n\nLooking at the graph we can clearly see that there are 3 Events with significantly lower mis-attribution of articles/headlines they are: The Farmington New Mexico shooting, the judgment against Jennifer Crumbley and the Prague university shooting."
  },
  {
    "objectID": "content/SlerkaProjekt.html#conlusion",
    "href": "content/SlerkaProjekt.html#conlusion",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Conlusion",
    "text": "Conlusion\nThe uniqueness of these three events is understandable; the shooting in Farmington was unique in the age of its victims (73-97) and the method of its perpetrator, the case against Jenifer Crumbley was poised to set a precedent in the USA (by now it has set it already) and the shooting in Prague has shown the danger of exporting the motivations and conditions of mass shooting from the USA into other countries with similar cultural contexts.\nHome"
  },
  {
    "objectID": "content/SlerkaProjekt.html#conclusion",
    "href": "content/SlerkaProjekt.html#conclusion",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Conclusion",
    "text": "Conclusion\nThe uniqueness of these three events is understandable; the shooting in Farmington was unique in the age of its victims (73-97) and the method of its perpetrator, the case against Jenifer Crumbley was poised to set a precedent in the USA (by now it has set it already) and the shooting in Prague has shown the danger of exporting the motivations and conditions of mass shooting from the USA into other countries with similar cultural contexts."
  },
  {
    "objectID": "SlerkaProjekt.html",
    "href": "SlerkaProjekt.html",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "",
    "text": "Given that the University shooting that happened on the 21 December 2023 was unprecedented in Czech history, I wondered whether it would be reflected as such in american media that has grown increasingly desensitized to news of mass shootings."
  },
  {
    "objectID": "SlerkaProjekt.html#getting-the-data",
    "href": "SlerkaProjekt.html#getting-the-data",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Getting the data",
    "text": "Getting the data\nI wanted to compare the mass shooting to comparable reporting about mass shootings using the same live-block format CNN used for the Prague shooting. I used the first 12 articles that popped up for the Google search ‘site:cnn.com “mass shooting” live-news’ and filtering for articles in 2023-2024.\nI created a list of the necessary URLs and a couple of helper functions: readUrlList, parseUrlList and generateTeiCorpus. They are simple for-loops that do what their name suggest. Let’s load them together with the packages we will need.\n\nlibrary(rvest)\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(janitor)\nlibrary(here)\nsource(here(\"helperCNNAnalysis.R\"))\n\nNow we can use them to read and parse the HTML of the CNN live-blogs. This may take some time so lets save it for later. If the code should be broken I have provided my own webscrape from 28.02.2024.\n\nhtmlList &lt;- readUrlList(urlList, silent = T)\nparsedDt &lt;- parseUrlList(htmlList, silent = T)\nsaveRDS(parsedDt, file = \"parsedDt_WebscrapingCNN.rds\")\nparsedDt\n\nAlternative:\n\nparsedDt &lt;- readRDS(here(\"parsedDt_WebscrapingCNN.rds\"))\nparsedDt\n\n\n\n  \n\n\n\nAs we can see, we don’t really see the article text (the last column “liveBlogUpdate”) we need to un-nest the data and fix the column names while we are at it.\n\nblogPostsExpanded &lt;- parsedDt %&gt;%\n  unnest(cols = c(liveBlogUpdate), names_sep = \"_blog\") %&gt;% \n  rename_with(~ str_replace_all(.x, \"[@\\\\$]\", \"\")) %&gt;% \n  select(mainEntityOfPage:datePublished, author:liveBlogUpdate_blogheadline, liveBlogUpdate_blogauthor:liveBlogUpdate_blogarticleBody)\n\nblogPostsExpanded"
  },
  {
    "objectID": "SlerkaProjekt.html#tei-conversion",
    "href": "SlerkaProjekt.html#tei-conversion",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "TEI conversion",
    "text": "TEI conversion\nSome tools require a TEI compatible corpus such as: https://voyant-tools.org/. We will now convert our data:\n\nblogTEI &lt;- blogPostsExpanded %&gt;% \n  mutate(\n    MetadataColumn = paste0(\"eventName: \", about$name, \"headline:\", liveBlogUpdate_blogheadline), \n    TextColumn = liveBlogUpdate_blogarticleBody\n  )\n\ndescription &lt;- paste0(\"A TEI corpus containg \", length(blogTEI), \" live blogpost from CNN about mass shootings.\")\n\nprague &lt;- generateTeiCorpus(MetadataColumn = blogTEI$MetadataColumn, TextColumn = blogTEI$TextColumn, MetadataSting = description, silent = T)"
  },
  {
    "objectID": "SlerkaProjekt.html#analysis-in-r",
    "href": "SlerkaProjekt.html#analysis-in-r",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Analysis in R",
    "text": "Analysis in R\nIf we want to keep analyzing in R we have multiple options. I would refer you to the great book ‘Text Mining with R’. Let’s use the tidytext and textdata packages to do a simple sentiment analysis. First we need to shape our data accordingly.\n\nlibrary(tidytext)\nlibrary(textdata)\n\n# Analysis\nreducedTb &lt;- blogPostsExpanded %&gt;% \n  unnest(cols = c(about)) %&gt;% \n  select(name, liveBlogUpdate_blogheadline, liveBlogUpdate_blogarticleBody) %&gt;% \n  rename(\"headline\" = liveBlogUpdate_blogheadline, \"text\" = liveBlogUpdate_blogarticleBody) %&gt;% \n  mutate(\n    text = tolower(text),\n    name = gsub(\"April 10, 2023: |April 11, 2023 - |Live updates: |March 27, 2023 |May 3, 2023 - |October 25, 2023 - \", \"\", name), \n    name = str_wrap(name, width = 40)\n    ) %&gt;%\n  unnest_tokens(word, text) %&gt;% \n  anti_join(stop_words, by = \"word\")\n\nNrcSentiments &lt;- get_sentiments(\"nrc\") # Get the sentiment database\n\n# Join our webscraped date with the sentiment file\narticlesSentiment &lt;- reducedTb %&gt;%\n  inner_join(NrcSentiments, by = \"word\", relationship = \"many-to-many\") %&gt;%\n  count(name, sentiment) %&gt;%\n  pivot_wider(names_from = sentiment, values_from = n) %&gt;% \n  mutate(\n    total = rowSums(select(., anger:trust)),\n    other = rowSums(select(., c(disgust, joy, surprise))),\n    reducedTb %&gt;% group_by(name) %&gt;% summarise(articles = n_distinct(headline)) %&gt;% select(\"articles\"), # Direct add articles\n    across(anger:other, ~ .x / total, .names = \"{.col}Prop\")\n  )\n\n# Pivot into a long format for the purpose of plotting\narticlesSentimentLong &lt;- articlesSentiment %&gt;% \n  select(name, angerProp, anticipationProp, fearProp, negativeProp:sadnessProp, trustProp, otherProp) %&gt;% \n  pivot_longer(cols = angerProp:otherProp,  names_to = \"emotion\", values_to = \"prevalence\") %&gt;% \n  mutate(emotion = gsub(\"Prop\", \"\", emotion))\n\nunique(articlesSentimentLong$emotion)\n\n[1] \"anger\"        \"anticipation\" \"fear\"         \"negative\"     \"positive\"    \n[6] \"sadness\"      \"trust\"        \"other\"       \n\n\nWe have reduced our data and joined it with the sentiment database nrc published by Saif Mohammad and Peter Turney. After that we computed rowSums and ‘rowAverages’, finally we converted the data into a long format for the purpose of plotting. For that we will be using the packages ggplot2 and scales.\n\nlibrary(ggplot2)\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nggplot(articlesSentimentLong) +\n  aes(x = name, y = prevalence, fill = emotion) +\n  geom_col() +\n  geom_text(\n    aes(label = percent(prevalence, accuracy = 0.1)),\n    nudge_y = if_else(articlesSentimentLong$prevalence &gt; .15, -.05, .05),  \n    size = 3, \n    color =  \"black\") + \n  coord_flip() +\n  theme_minimal() + \n  theme(axis.ticks = element_blank(), \n        axis.text.x = element_blank(), \n        axis.title.x = element_blank(), \n        axis.title.y = element_blank(), \n        legend.position = \"none\") +\n  facet_grid(~ emotion)"
  },
  {
    "objectID": "SlerkaProjekt.html#expandin-on-that-analysis-latent-dirichlet-allocation",
    "href": "SlerkaProjekt.html#expandin-on-that-analysis-latent-dirichlet-allocation",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Expandin on that analysis: Latent Dirichlet allocation",
    "text": "Expandin on that analysis: Latent Dirichlet allocation\nLatent Dirichlet allocation (LDA) is a particularly popular method for fitting a topic model. It treats each document as a mixture of topics, and each topic as a mixture of words. We will use it to give some oomph to our analysis. For that we will be using the package topicmodels. We will also have to adapt the shape of our data:\n\nlibrary(topicmodels)\n\nremoveWords &lt;- c(\"cnn\", \"p.m\")\ntoRemoveDf &lt;- tibble(document = NA, word = removeWords, n = 1)\n\n# Dataformatting\n# Need one-term-per-document-per-row\n\nDtmData &lt;- reducedTb %&gt;% \n  group_by(name, headline) %&gt;% \n  count(word, sort = T) %&gt;% \n  ungroup() %&gt;% \n  mutate(document = paste0(name, \"_\", headline)) %&gt;% \n  select(document, word, n) %&gt;% \n  anti_join(toRemoveDf, by = \"word\")\n\nhead(DtmData, 5)\n\n\n\n  \n\n\n\nNow that our data is in an appropriate format we can start modeling. As we know that there are 12 Events we have scraped from the Web we can input that for gaining an optimal model. (I have attempted other values, the results were less thatn stellar.)\n\ncastData &lt;- cast_tdm(data = DtmData, term = document, document = word, value = n) # reverse necessary\n\ncastData\n\n&lt;&lt;TermDocumentMatrix (terms: 432, documents: 3991)&gt;&gt;\nNon-/sparse entries: 20266/1703846\nSparsity           : 99%\nMaximal term length: 180\nWeighting          : term frequency (tf)\n\nmodel1 &lt;- LDA(castData, k = 12, control = list(seed = 1234)) # reverses, see above\n  \nmodel1\n\nA LDA_VEM topic model with 12 topics.\n\nmodel1Topics &lt;- tidytext::tidy(model1, matrix = \"beta\")\n\nmodel1Topics\n\n\n\n  \n\n\n\nYou might have noticed the issue with the reverse naming of document and word. For some reason there happens a switch in the LDA() step, that I was unable to diagnose, so this is my shoddy workaround. Now that we have the model we can look how certain terms are present in the models 12 topics. Remember that the topics were set by the model itself and not by us. Therefor we can evaluate if the topic are sensible to our human preferences.\n\nshootingTopTerms &lt;- model1Topics %&gt;%\n  group_by(topic) %&gt;%\n  slice_max(beta, n = 10) %&gt;% \n  ungroup() %&gt;%\n  arrange(topic, -beta)\n\nshootingTopTerms %&gt;%\n  mutate(term = reorder_within(term, beta, topic)) %&gt;%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered()\n\n\n\n\nWe are mostly interested in plot nr. 11 that is showing the language used during the reporting on the Prague mass shooting. To my sensibilities the graph make sense and so I will continue with the analysis. To determine whether the Prague shooting was a routing reporting experience for the writers at CNN we can look whether the articles themselves are significantly different. For that purpose we will separate the individual articles from their Events and look how many the model can correctly allocate to the correct topic.\n\nmodel1Gamma &lt;- tidytext::tidy(model1, matrix = \"gamma\")\n\nmodel1Gamma\n\n\n\n  \n\n\nseparatedGamma &lt;- model1Gamma %&gt;%\n  separate(document, c(\"Event\", \"Headline\"), sep = \"_\", convert = TRUE)\n\nseparatedGamma\n\n\n\n  \n\n\nseparatedGamma %&gt;%\n  mutate(title = reorder(Event, gamma * topic)) %&gt;%\n  ggplot(aes(factor(topic), gamma)) +\n  geom_boxplot() +\n  facet_wrap(~ Event) +\n  labs(x = \"topic\", y = expression(gamma))\n\n\n\n\nLooking at the graph we can clearly see that there are 3 Events with significantly lower mis-attribution of articles/headlines they are: The Farmington New Mexico shooting, the judgment against Jennifer Crumbley and the Prague university shooting."
  },
  {
    "objectID": "SlerkaProjekt.html#conclusion",
    "href": "SlerkaProjekt.html#conclusion",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Conclusion",
    "text": "Conclusion\nThe uniqueness of these three events is understandable; the shooting in Farmington was unique in the age of its victims (73-97) and the method of its perpetrator, the case against Jenifer Crumbley was poised to set a precedent in the USA (by now it has set it already) and the shooting in Prague has shown the danger of exporting the motivations and conditions of mass shooting from the USA into other countries with similar cultural contexts."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\nCharles University, Prague, Czech Republic\nSociology | Sept 2021 - present\nTechnical University Berlin, Berlin, Germany\nBc. Architecture | Sept 2019 - June 2021"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\nPAQ Research | Data Analyst | September 2022 - present\nInbaze | External: German Lecturer | October 2021 - present"
  },
  {
    "objectID": "SlerkaProjekt.html#expanding-on-that-analysis-latent-dirichlet-allocation",
    "href": "SlerkaProjekt.html#expanding-on-that-analysis-latent-dirichlet-allocation",
    "title": "Analyzing the CNN coverage of the Prague University shooting",
    "section": "Expanding on that analysis: Latent Dirichlet allocation",
    "text": "Expanding on that analysis: Latent Dirichlet allocation\nLatent Dirichlet allocation (LDA) is a particularly popular method for fitting a topic model. It treats each document as a mixture of topics, and each topic as a mixture of words. We will use it to give some oomph to our analysis. For that we will be using the package topicmodels. We will also have to adapt the shape of our data:\n\nlibrary(topicmodels)\n\nremoveWords &lt;- c(\"cnn\", \"p.m\")\ntoRemoveDf &lt;- tibble(document = NA, word = removeWords, n = 1)\n\n# Dataformatting\n# Need one-term-per-document-per-row\n\nDtmData &lt;- reducedTb %&gt;% \n  group_by(name, headline) %&gt;% \n  count(word, sort = T) %&gt;% \n  ungroup() %&gt;% \n  mutate(document = paste0(name, \"_\", headline)) %&gt;% \n  select(document, word, n) %&gt;% \n  anti_join(toRemoveDf, by = \"word\")\n\nhead(DtmData, 5)\n\n\n\n  \n\n\n\nNow that our data is in an appropriate format we can start modeling. As we know that there are 12 Events we have scraped from the Web we can input that for gaining an optimal model. (I have attempted other values, the results were less than stellar.)\n\ncastData &lt;- cast_tdm(data = DtmData, term = document, document = word, value = n) # reverse necessary\n\ncastData\n\n&lt;&lt;TermDocumentMatrix (terms: 432, documents: 3991)&gt;&gt;\nNon-/sparse entries: 20266/1703846\nSparsity           : 99%\nMaximal term length: 180\nWeighting          : term frequency (tf)\n\nmodel1 &lt;- LDA(castData, k = 12, control = list(seed = 1234)) # reverses, see above\n  \nmodel1\n\nA LDA_VEM topic model with 12 topics.\n\nmodel1Topics &lt;- tidytext::tidy(model1, matrix = \"beta\")\n\nmodel1Topics\n\n\n\n  \n\n\n\nYou might have noticed the issue with the reverse naming of document and word. For some reason there happens a switch in the LDA() step, that I was unable to diagnose, so this is my shoddy workaround. Now that we have the model we can look how certain terms are present in the models 12 topics. Remember that the topics were set by the model itself and not by us. Therefor we can evaluate if the topic are sensible to our human preferences.\n\nshootingTopTerms &lt;- model1Topics %&gt;%\n  group_by(topic) %&gt;%\n  slice_max(beta, n = 10) %&gt;% \n  ungroup() %&gt;%\n  arrange(topic, -beta)\n\nshootingTopTerms %&gt;%\n  mutate(term = reorder_within(term, beta, topic)) %&gt;%\n  ggplot(aes(beta, term, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\") +\n  scale_y_reordered()\n\n\n\n\nWe are mostly interested in plot nr. 11 that is showing the language used during the reporting on the Prague mass shooting. To my sensibilities the graph make sense and so I will continue with the analysis. To determine whether the Prague shooting was a routing reporting experience for the writers at CNN we can look whether the articles themselves are significantly different. For that purpose we will separate the individual articles from their Events and look how many the model can correctly allocate to the correct topic.\n\nmodel1Gamma &lt;- tidytext::tidy(model1, matrix = \"gamma\")\n\nmodel1Gamma\n\n\n\n  \n\n\nseparatedGamma &lt;- model1Gamma %&gt;%\n  separate(document, c(\"Event\", \"Headline\"), sep = \"_\", convert = TRUE)\n\nseparatedGamma\n\n\n\n  \n\n\nseparatedGamma %&gt;%\n  mutate(title = reorder(Event, gamma * topic)) %&gt;%\n  ggplot(aes(factor(topic), gamma)) +\n  geom_boxplot() +\n  facet_wrap(~ Event) +\n  labs(x = \"topic\", y = expression(gamma))\n\n\n\n\nLooking at the graph we can clearly see that there are 3 Events with significantly lower mis-attribution of articles/headlines they are: The Farmington New Mexico shooting, the judgment against Jennifer Crumbley and the Prague university shooting."
  }
]